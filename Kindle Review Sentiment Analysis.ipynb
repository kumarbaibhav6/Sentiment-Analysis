{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a3b6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11539</td>\n",
       "      <td>B0033UV8HI</td>\n",
       "      <td>[8, 10]</td>\n",
       "      <td>3</td>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>09 2, 2010</td>\n",
       "      <td>A3HHXRELK8BHQG</td>\n",
       "      <td>Ridley</td>\n",
       "      <td>Entertaining But Average</td>\n",
       "      <td>1283385600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5957</td>\n",
       "      <td>B002HJV4DE</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>10 8, 2013</td>\n",
       "      <td>A2RGNZ0TRF578I</td>\n",
       "      <td>Holly Butler</td>\n",
       "      <td>Terrific menage scenes!</td>\n",
       "      <td>1381190400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9146</td>\n",
       "      <td>B002ZG96I4</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>04 11, 2014</td>\n",
       "      <td>A3S0H2HV6U1I7F</td>\n",
       "      <td>Merissa</td>\n",
       "      <td>Snapdragon Alley</td>\n",
       "      <td>1397174400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7038</td>\n",
       "      <td>B002QHWOEU</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>3</td>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>07 5, 2014</td>\n",
       "      <td>AC4OQW3GZ919J</td>\n",
       "      <td>Cleargrace</td>\n",
       "      <td>very light murder cozy</td>\n",
       "      <td>1404518400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1776</td>\n",
       "      <td>B001A06VJ8</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>12 31, 2012</td>\n",
       "      <td>A3C9V987IQHOQD</td>\n",
       "      <td>Rjostler</td>\n",
       "      <td>Book</td>\n",
       "      <td>1356912000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0        asin  helpful  rating  \\\n",
       "0             0       11539  B0033UV8HI  [8, 10]       3   \n",
       "1             1        5957  B002HJV4DE   [1, 1]       5   \n",
       "2             2        9146  B002ZG96I4   [0, 0]       3   \n",
       "3             3        7038  B002QHWOEU   [1, 3]       3   \n",
       "4             4        1776  B001A06VJ8   [0, 1]       4   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  Jace Rankin may be short, but he's nothing to ...   09 2, 2010   \n",
       "1  Great short read.  I didn't want to put it dow...   10 8, 2013   \n",
       "2  I'll start by saying this is the first of four...  04 11, 2014   \n",
       "3  Aggie is Angela Lansbury who carries pocketboo...   07 5, 2014   \n",
       "4  I did not expect this type of book to be in li...  12 31, 2012   \n",
       "\n",
       "       reviewerID  reviewerName                   summary  unixReviewTime  \n",
       "0  A3HHXRELK8BHQG        Ridley  Entertaining But Average      1283385600  \n",
       "1  A2RGNZ0TRF578I  Holly Butler   Terrific menage scenes!      1381190400  \n",
       "2  A3S0H2HV6U1I7F       Merissa          Snapdragon Alley      1397174400  \n",
       "3   AC4OQW3GZ919J    Cleargrace    very light murder cozy      1404518400  \n",
       "4  A3C9V987IQHOQD      Rjostler                      Book      1356912000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read the dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('all_kindle_review.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c0aae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['reviewText','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44af03f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText    0\n",
       "rating        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0c0b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 4, 2, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e4e97d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    3000\n",
       "4    3000\n",
       "3    2000\n",
       "2    2000\n",
       "1    2000\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7db81d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating  review\n",
       "0  Jace Rankin may be short, but he's nothing to ...       3       1\n",
       "1  Great short read.  I didn't want to put it dow...       5       1\n",
       "2  I'll start by saying this is the first of four...       3       1\n",
       "3  Aggie is Angela Lansbury who carries pocketboo...       3       1\n",
       "4  I did not expect this type of book to be in li...       4       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing and Cleaning\n",
    "data['review'] = data['rating'].apply(lambda x: 0 if x < 3 else 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83fc7d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8000\n",
       "0    4000\n",
       "Name: review, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c62b60de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jace rankin may be short, but he's nothing to ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great short read.  i didn't want to put it dow...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'll start by saying this is the first of four...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aggie is angela lansbury who carries pocketboo...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i did not expect this type of book to be in li...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating  review\n",
       "0  jace rankin may be short, but he's nothing to ...       3       1\n",
       "1  great short read.  i didn't want to put it dow...       5       1\n",
       "2  i'll start by saying this is the first of four...       3       1\n",
       "3  aggie is angela lansbury who carries pocketboo...       3       1\n",
       "4  i did not expect this type of book to be in li...       4       1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lowercase the text\n",
    "data['reviewText']=data['reviewText'].str.lower()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "932ea6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kumarbaibhav/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/kumarbaibhav/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/kumarbaibhav/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b61c736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8beeabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v9/vhgfpqqn68d5z4pqh22hxlf40000gn/T/ipykernel_1218/1696490515.py:8: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  data['reviewText']=data['reviewText'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text())\n"
     ]
    }
   ],
   "source": [
    "# Removing special characters\n",
    "data['reviewText']=data['reviewText'].apply(lambda x:re.sub('[^a-z A-z 0-9-]+', '',x))\n",
    "# Remove the stopswords\n",
    "data['reviewText']=data['reviewText'].apply(lambda x:\" \".join([y for y in x.split() if y not in stopwords.words('english')]))\n",
    "# Remove url \n",
    "data['reviewText']=data['reviewText'].apply(lambda x: re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '' , str(x)))\n",
    "# Remove html tags\n",
    "data['reviewText']=data['reviewText'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text())\n",
    "# Remove any additional spaces\n",
    "data['reviewText']=data['reviewText'].apply(lambda x: \" \".join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e37626a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jace rankin may short hes nothing mess man hau...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great short read didnt want put read one sitti...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ill start saying first four books wasnt expect...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aggie angela lansbury carries pocketbooks inst...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expect type book library pleased find price right</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating  review\n",
       "0  jace rankin may short hes nothing mess man hau...       3       1\n",
       "1  great short read didnt want put read one sitti...       5       1\n",
       "2  ill start saying first four books wasnt expect...       3       1\n",
       "3  aggie angela lansbury carries pocketbooks inst...       3       1\n",
       "4  expect type book library pleased find price right       4       1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0913fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#create function for lemmatization\n",
    "def lemmatize(x):\n",
    "    \n",
    "    return \" \".join([lemmatizer.lemmatize(word,pos='v') for word in x.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d0b5274",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jace rankin may short hes nothing mess man hau...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great short read didnt want put read one sit s...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ill start say first four book wasnt expect 34c...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aggie angela lansbury carry pocketbooks instea...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expect type book library please find price right</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating  review\n",
       "0  jace rankin may short hes nothing mess man hau...       3       1\n",
       "1  great short read didnt want put read one sit s...       5       1\n",
       "2  ill start say first four book wasnt expect 34c...       3       1\n",
       "3  aggie angela lansbury carry pocketbooks instea...       3       1\n",
       "4   expect type book library please find price right       4       1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply to review text column\n",
    "data['reviewText'] = data['reviewText'].apply(lambda x: lemmatize(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f4e470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(data['reviewText'],data['review'],test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c875893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply BOW \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer()\n",
    "X_train_bow = bow.fit_transform(X_train).toarray()\n",
    "X_test_bow = bow.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dc7eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply TFIDF \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train).toarray()\n",
    "X_test_tfidf = tfidf.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf331fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply naive bayes algorithm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_model_bow = GaussianNB().fit(X_train_bow,y_train)\n",
    "nb_model_tfidf = GaussianNB().fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96bffc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics for BOW Model-------------------------------\n",
      "[[522 263]\n",
      " [744 871]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.66      0.51       785\n",
      "           1       0.77      0.54      0.63      1615\n",
      "\n",
      "    accuracy                           0.58      2400\n",
      "   macro avg       0.59      0.60      0.57      2400\n",
      "weighted avg       0.65      0.58      0.59      2400\n",
      "\n",
      "0.5804166666666667\n",
      "\n",
      "\n",
      "Performance metrics for TFIDF Model-------------------------------\n",
      "[[511 274]\n",
      " [736 879]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.65      0.50       785\n",
      "           1       0.76      0.54      0.64      1615\n",
      "\n",
      "    accuracy                           0.58      2400\n",
      "   macro avg       0.59      0.60      0.57      2400\n",
      "weighted avg       0.65      0.58      0.59      2400\n",
      "\n",
      "0.5791666666666667\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check performance metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "y_pred_bow = nb_model_bow.predict(X_test_bow)\n",
    "y_pred_tfidf = nb_model_tfidf.predict(X_test_tfidf)\n",
    "print(f'Performance metrics for BOW Model-------------------------------')\n",
    "print(f'{confusion_matrix(y_test,y_pred_bow)}')\n",
    "print(f'{classification_report(y_test,y_pred_bow)}')\n",
    "print(f'{accuracy_score(y_test,y_pred_bow)}')\n",
    "print('\\n')\n",
    "print(f'Performance metrics for TFIDF Model-------------------------------')\n",
    "print(f'{confusion_matrix(y_test,y_pred_tfidf)}')\n",
    "print(f'{classification_report(y_test,y_pred_tfidf)}')\n",
    "print(f'{accuracy_score(y_test,y_pred_tfidf)}')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5d829db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of words for every sentence and append into a list\n",
    "words = []\n",
    "for index,row in data.iterrows():\n",
    "    words.append([i for i in row['reviewText'].split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3c0935e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#implement Word2Vec model\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import gensim.downloader as api\n",
    "#wv = api.load('word2vec-google-news-300')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "412c1395",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wv\u001b[38;5;241m.\u001b[39mmost_similar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbadass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wv' is not defined"
     ]
    }
   ],
   "source": [
    "wv.most_similar('badass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06d8b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec model\n",
    "word2vec_model = Word2Vec(sentences = words)\n",
    "#apply average word2vec\n",
    "def avg_word2vec(doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    #sent = [word for word in doc if word in model.wv.index_to_key]\n",
    "    #print(sent)\n",
    "    return np.mean([word2vec_model.wv[word] for word in doc if word in word2vec_model.wv.index_to_key],axis=0)\n",
    "                #or [np.zeros(len(model.wv.index_to_key))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a66b7597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrained model\n",
    "def avg_word2vec(doc):\n",
    "    # Remove out-of-vocabulary words and compute the mean of the word vectors\n",
    "    return np.mean([wv[word] for word in doc if word in wv.index_to_key], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b57df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'C:/Users/gaya/Desktop/project/word2vec_model.model'\n",
    "word2vec_model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5449b59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd27c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5da9813d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jace',\n",
       " 'rankin',\n",
       " 'may',\n",
       " 'short',\n",
       " 'hes',\n",
       " 'nothing',\n",
       " 'mess',\n",
       " 'man',\n",
       " 'haul',\n",
       " 'saloon',\n",
       " 'undertaker',\n",
       " 'know',\n",
       " 'hes',\n",
       " 'famous',\n",
       " 'bounty',\n",
       " 'hunter',\n",
       " 'oregon',\n",
       " '1890s',\n",
       " 'shoot',\n",
       " 'man',\n",
       " 'saloon',\n",
       " 'finish',\n",
       " 'years',\n",
       " 'long',\n",
       " 'quest',\n",
       " 'avenge',\n",
       " 'sisters',\n",
       " 'murder',\n",
       " 'try',\n",
       " 'figure',\n",
       " 'next',\n",
       " 'snotty-nosed',\n",
       " 'farm',\n",
       " 'boy',\n",
       " 'rescue',\n",
       " 'gang',\n",
       " 'bully',\n",
       " 'offer',\n",
       " 'money',\n",
       " 'kill',\n",
       " 'man',\n",
       " 'force',\n",
       " 'ranch',\n",
       " 'reluctantly',\n",
       " 'agree',\n",
       " 'bring',\n",
       " 'man',\n",
       " 'justice',\n",
       " 'kill',\n",
       " 'outright',\n",
       " 'first',\n",
       " 'need',\n",
       " 'tell',\n",
       " 'sisters',\n",
       " 'widower',\n",
       " 'newskyla',\n",
       " 'kyle',\n",
       " 'springer',\n",
       " 'bailey',\n",
       " 'rid',\n",
       " 'trail',\n",
       " 'sleep',\n",
       " 'grind',\n",
       " 'past',\n",
       " 'month',\n",
       " 'try',\n",
       " 'find',\n",
       " 'jace',\n",
       " 'want',\n",
       " 'revenge',\n",
       " 'man',\n",
       " 'kill',\n",
       " 'husband',\n",
       " 'take',\n",
       " 'ranch',\n",
       " 'amongst',\n",
       " 'crimes',\n",
       " 'shes',\n",
       " 'keen',\n",
       " 'detour',\n",
       " 'jace',\n",
       " 'want',\n",
       " 'take',\n",
       " 'realize',\n",
       " 'shes',\n",
       " 'options',\n",
       " 'hide',\n",
       " 'behind',\n",
       " 'boy',\n",
       " 'persona',\n",
       " 'best',\n",
       " 'try',\n",
       " 'keep',\n",
       " 'pace',\n",
       " 'confrontation',\n",
       " 'along',\n",
       " 'way',\n",
       " 'get',\n",
       " 'shoot',\n",
       " 'jace',\n",
       " 'discover',\n",
       " 'kyles',\n",
       " 'kyla',\n",
       " 'come',\n",
       " 'clean',\n",
       " 'whole',\n",
       " 'reason',\n",
       " 'need',\n",
       " 'scoundrel',\n",
       " 'dead',\n",
       " 'hope',\n",
       " 'hell',\n",
       " 'still',\n",
       " 'help',\n",
       " 'herthe',\n",
       " 'book',\n",
       " 'share',\n",
       " 'touch',\n",
       " 'moments',\n",
       " 'slow-blooming',\n",
       " 'romance',\n",
       " 'kyla',\n",
       " 'find',\n",
       " 'good',\n",
       " 'reason',\n",
       " 'fear',\n",
       " 'men',\n",
       " 'hide',\n",
       " 'behind',\n",
       " 'boys',\n",
       " 'persona',\n",
       " 'watch',\n",
       " 'jace',\n",
       " 'slowly',\n",
       " 'pull',\n",
       " 'shell',\n",
       " 'help',\n",
       " 'conquer',\n",
       " 'fear',\n",
       " 'endear',\n",
       " 'pain',\n",
       " 'real',\n",
       " 'deeply-rooted',\n",
       " 'didnt',\n",
       " 'disappear',\n",
       " 'face',\n",
       " 'sexiness',\n",
       " 'neither',\n",
       " 'understandable',\n",
       " 'aversion',\n",
       " 'marriage',\n",
       " 'magically',\n",
       " 'disappear',\n",
       " 'round',\n",
       " 'nookie',\n",
       " 'would',\n",
       " 'man',\n",
       " 'whos',\n",
       " 'drift',\n",
       " 'town',\n",
       " 'town',\n",
       " 'entire',\n",
       " 'adult',\n",
       " 'life',\n",
       " '-',\n",
       " 'man',\n",
       " 'whos',\n",
       " 'kill',\n",
       " 'fair',\n",
       " 'share',\n",
       " 'men',\n",
       " 'along',\n",
       " 'way',\n",
       " '-',\n",
       " 'feel',\n",
       " 'hed',\n",
       " 'make',\n",
       " 'good',\n",
       " 'husband',\n",
       " 'father',\n",
       " 'theyre',\n",
       " 'walk',\n",
       " 'wound',\n",
       " 'unique',\n",
       " 'position',\n",
       " 'help',\n",
       " 'need',\n",
       " 'time',\n",
       " 'realize',\n",
       " 'ithowever',\n",
       " 'pack',\n",
       " 'burst',\n",
       " 'favorite',\n",
       " 'theme',\n",
       " '-',\n",
       " 'old',\n",
       " 'west',\n",
       " 'set',\n",
       " 'heroine',\n",
       " 'pass',\n",
       " 'male',\n",
       " 'morally',\n",
       " 'ambiguous',\n",
       " 'hero',\n",
       " 'wound',\n",
       " 'souls',\n",
       " 'road',\n",
       " 'romance',\n",
       " 'kitchen',\n",
       " 'sink',\n",
       " '-',\n",
       " 'certaindistance',\n",
       " 'write',\n",
       " 'keep',\n",
       " 'get',\n",
       " 'carry',\n",
       " 'away',\n",
       " 'character',\n",
       " 'distinct',\n",
       " 'fully-formed',\n",
       " 'couldnt',\n",
       " 'point',\n",
       " 'glare',\n",
       " 'instance',\n",
       " 'bland',\n",
       " 'tell',\n",
       " 'anything',\n",
       " 'never',\n",
       " 'felt',\n",
       " 'really',\n",
       " 'invest',\n",
       " 'enjoy',\n",
       " 'quite',\n",
       " 'bite',\n",
       " 'excite',\n",
       " 'trip',\n",
       " 'watch',\n",
       " 'far',\n",
       " 'away',\n",
       " 'definitely',\n",
       " 'wasnt',\n",
       " 'run',\n",
       " 'alongside',\n",
       " 'add',\n",
       " 'hasty',\n",
       " 'tidy',\n",
       " 'end',\n",
       " 'book',\n",
       " 'leave',\n",
       " 'feel',\n",
       " 'bite',\n",
       " 'less',\n",
       " 'completely',\n",
       " 'satisfiedi',\n",
       " 'enjoy',\n",
       " 'book',\n",
       " 'cant',\n",
       " 'say',\n",
       " 'average',\n",
       " 'id',\n",
       " 'still',\n",
       " 'read',\n",
       " 'another',\n",
       " 'book',\n",
       " 'authornote',\n",
       " 'read',\n",
       " 're-released',\n",
       " 'ebook',\n",
       " 'version',\n",
       " 'notice',\n",
       " 'lot',\n",
       " 'format',\n",
       " 'errors',\n",
       " 'miss',\n",
       " 'word',\n",
       " 'mentally',\n",
       " 'edit',\n",
       " 'read',\n",
       " 'sentence',\n",
       " 'make',\n",
       " 'sense',\n",
       " 'wasnt',\n",
       " 'bad',\n",
       " 'little',\n",
       " 'distract']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#words for the 1st sentence\n",
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5955382f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 12000/12000 [00:05<00:00, 2022.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "#apply for the entire sentences\n",
    "import numpy as np\n",
    "X=[]\n",
    "for i in tqdm(range(len(words))):\n",
    "    X.append(avg_word2vec(words[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80e168b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check shape of vector embedding for a document\n",
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da685b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 100)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array(X)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "575c9dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].reshape(1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "801e9fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e79e0564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 153/12000 [00:39<51:06,  3.86it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(words))):\n\u001b[0;32m----> 4\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pd\u001b[38;5;241m.\u001b[39mDataFrame(X[i]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X))], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py:381\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03mConcatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m1   3   4\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    368\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    369\u001b[0m     objs,\n\u001b[1;32m    370\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    379\u001b[0m )\n\u001b[0;32m--> 381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    612\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    614\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 616\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[1;32m    617\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m    618\u001b[0m )\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy:\n\u001b[1;32m    620\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/concat.py:205\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    202\u001b[0m concat_plan \u001b[38;5;241m=\u001b[39m _combine_concat_plans(concat_plans, concat_axis)\n\u001b[1;32m    203\u001b[0m blocks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m placement, join_units \u001b[38;5;129;01min\u001b[39;00m concat_plan:\n\u001b[1;32m    206\u001b[0m     unit \u001b[38;5;241m=\u001b[39m join_units[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    207\u001b[0m     blk \u001b[38;5;241m=\u001b[39m unit\u001b[38;5;241m.\u001b[39mblock\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/concat.py:744\u001b[0m, in \u001b[0;36m_combine_concat_plans\u001b[0;34m(plans, concat_axis)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_ended[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlan shapes are not aligned\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 744\u001b[0m placements, units \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mnext_items)\n\u001b[1;32m    746\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlen\u001b[39m, placements))\n\u001b[1;32m    747\u001b[0m min_len, max_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(lengths), \u001b[38;5;28mmax\u001b[39m(lengths)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#appending all the vectors after using avg word2vec into a dataframe\n",
    "df = pd.DataFrame()\n",
    "for i in tqdm(range(len(words))):\n",
    "    df = pd.concat([pd.DataFrame(X[i].reshape(1, -1)) for i in range(len(X))], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc1e0004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.020624</td>\n",
       "      <td>0.290489</td>\n",
       "      <td>-0.207166</td>\n",
       "      <td>-0.089109</td>\n",
       "      <td>0.014833</td>\n",
       "      <td>-0.474143</td>\n",
       "      <td>0.189333</td>\n",
       "      <td>0.530447</td>\n",
       "      <td>-0.180703</td>\n",
       "      <td>-0.247802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495438</td>\n",
       "      <td>0.060727</td>\n",
       "      <td>0.007973</td>\n",
       "      <td>0.108346</td>\n",
       "      <td>0.424585</td>\n",
       "      <td>0.117388</td>\n",
       "      <td>0.230643</td>\n",
       "      <td>-0.454489</td>\n",
       "      <td>0.036424</td>\n",
       "      <td>-0.022297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.036068</td>\n",
       "      <td>0.164903</td>\n",
       "      <td>-0.198505</td>\n",
       "      <td>0.190031</td>\n",
       "      <td>-0.106824</td>\n",
       "      <td>-0.548203</td>\n",
       "      <td>0.087713</td>\n",
       "      <td>0.760150</td>\n",
       "      <td>-0.502068</td>\n",
       "      <td>-0.783824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381369</td>\n",
       "      <td>0.170673</td>\n",
       "      <td>-0.185213</td>\n",
       "      <td>0.276593</td>\n",
       "      <td>0.814066</td>\n",
       "      <td>0.399272</td>\n",
       "      <td>0.251647</td>\n",
       "      <td>-0.380382</td>\n",
       "      <td>-0.173469</td>\n",
       "      <td>-0.159441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.171994</td>\n",
       "      <td>0.380069</td>\n",
       "      <td>-0.126491</td>\n",
       "      <td>0.216998</td>\n",
       "      <td>-0.147193</td>\n",
       "      <td>-0.456888</td>\n",
       "      <td>0.173166</td>\n",
       "      <td>0.703797</td>\n",
       "      <td>-0.480871</td>\n",
       "      <td>-0.521802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335733</td>\n",
       "      <td>0.138489</td>\n",
       "      <td>-0.017147</td>\n",
       "      <td>0.224223</td>\n",
       "      <td>0.813675</td>\n",
       "      <td>0.354883</td>\n",
       "      <td>0.284375</td>\n",
       "      <td>-0.369756</td>\n",
       "      <td>-0.171590</td>\n",
       "      <td>-0.127394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.250549</td>\n",
       "      <td>0.368768</td>\n",
       "      <td>-0.056130</td>\n",
       "      <td>0.201408</td>\n",
       "      <td>-0.159876</td>\n",
       "      <td>-0.356677</td>\n",
       "      <td>-0.119307</td>\n",
       "      <td>0.579250</td>\n",
       "      <td>-0.471635</td>\n",
       "      <td>-0.352775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244894</td>\n",
       "      <td>0.163364</td>\n",
       "      <td>0.060336</td>\n",
       "      <td>0.113170</td>\n",
       "      <td>0.639825</td>\n",
       "      <td>0.581436</td>\n",
       "      <td>0.089397</td>\n",
       "      <td>-0.186249</td>\n",
       "      <td>-0.067916</td>\n",
       "      <td>-0.206023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.216182</td>\n",
       "      <td>0.245601</td>\n",
       "      <td>0.183347</td>\n",
       "      <td>0.588376</td>\n",
       "      <td>0.083498</td>\n",
       "      <td>-0.610692</td>\n",
       "      <td>0.323728</td>\n",
       "      <td>0.837952</td>\n",
       "      <td>-0.447431</td>\n",
       "      <td>-0.581264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282189</td>\n",
       "      <td>0.142825</td>\n",
       "      <td>-0.118187</td>\n",
       "      <td>0.169801</td>\n",
       "      <td>0.740734</td>\n",
       "      <td>0.231928</td>\n",
       "      <td>0.244710</td>\n",
       "      <td>-0.208078</td>\n",
       "      <td>-0.378202</td>\n",
       "      <td>0.010910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.020624  0.290489 -0.207166 -0.089109  0.014833 -0.474143  0.189333   \n",
       "1  0.036068  0.164903 -0.198505  0.190031 -0.106824 -0.548203  0.087713   \n",
       "2 -0.171994  0.380069 -0.126491  0.216998 -0.147193 -0.456888  0.173166   \n",
       "3 -0.250549  0.368768 -0.056130  0.201408 -0.159876 -0.356677 -0.119307   \n",
       "4 -0.216182  0.245601  0.183347  0.588376  0.083498 -0.610692  0.323728   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0  0.530447 -0.180703 -0.247802  ...  0.495438  0.060727  0.007973  0.108346   \n",
       "1  0.760150 -0.502068 -0.783824  ...  0.381369  0.170673 -0.185213  0.276593   \n",
       "2  0.703797 -0.480871 -0.521802  ...  0.335733  0.138489 -0.017147  0.224223   \n",
       "3  0.579250 -0.471635 -0.352775  ...  0.244894  0.163364  0.060336  0.113170   \n",
       "4  0.837952 -0.447431 -0.581264  ...  0.282189  0.142825 -0.118187  0.169801   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0  0.424585  0.117388  0.230643 -0.454489  0.036424 -0.022297  \n",
       "1  0.814066  0.399272  0.251647 -0.380382 -0.173469 -0.159441  \n",
       "2  0.813675  0.354883  0.284375 -0.369756 -0.171590 -0.127394  \n",
       "3  0.639825  0.581436  0.089397 -0.186249 -0.067916 -0.206023  \n",
       "4  0.740734  0.231928  0.244710 -0.208078 -0.378202  0.010910  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe with each sentence represented as a 300 dimensional vector \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9c62494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.020624</td>\n",
       "      <td>0.290489</td>\n",
       "      <td>-0.207166</td>\n",
       "      <td>-0.089109</td>\n",
       "      <td>0.014833</td>\n",
       "      <td>-0.474143</td>\n",
       "      <td>0.189333</td>\n",
       "      <td>0.530447</td>\n",
       "      <td>-0.180703</td>\n",
       "      <td>-0.247802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060727</td>\n",
       "      <td>0.007973</td>\n",
       "      <td>0.108346</td>\n",
       "      <td>0.424585</td>\n",
       "      <td>0.117388</td>\n",
       "      <td>0.230643</td>\n",
       "      <td>-0.454489</td>\n",
       "      <td>0.036424</td>\n",
       "      <td>-0.022297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.036068</td>\n",
       "      <td>0.164903</td>\n",
       "      <td>-0.198505</td>\n",
       "      <td>0.190031</td>\n",
       "      <td>-0.106824</td>\n",
       "      <td>-0.548203</td>\n",
       "      <td>0.087713</td>\n",
       "      <td>0.760150</td>\n",
       "      <td>-0.502068</td>\n",
       "      <td>-0.783824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170673</td>\n",
       "      <td>-0.185213</td>\n",
       "      <td>0.276593</td>\n",
       "      <td>0.814066</td>\n",
       "      <td>0.399272</td>\n",
       "      <td>0.251647</td>\n",
       "      <td>-0.380382</td>\n",
       "      <td>-0.173469</td>\n",
       "      <td>-0.159441</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.171994</td>\n",
       "      <td>0.380069</td>\n",
       "      <td>-0.126491</td>\n",
       "      <td>0.216998</td>\n",
       "      <td>-0.147193</td>\n",
       "      <td>-0.456888</td>\n",
       "      <td>0.173166</td>\n",
       "      <td>0.703797</td>\n",
       "      <td>-0.480871</td>\n",
       "      <td>-0.521802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138489</td>\n",
       "      <td>-0.017147</td>\n",
       "      <td>0.224223</td>\n",
       "      <td>0.813675</td>\n",
       "      <td>0.354883</td>\n",
       "      <td>0.284375</td>\n",
       "      <td>-0.369756</td>\n",
       "      <td>-0.171590</td>\n",
       "      <td>-0.127394</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.250549</td>\n",
       "      <td>0.368768</td>\n",
       "      <td>-0.056130</td>\n",
       "      <td>0.201408</td>\n",
       "      <td>-0.159876</td>\n",
       "      <td>-0.356677</td>\n",
       "      <td>-0.119307</td>\n",
       "      <td>0.579250</td>\n",
       "      <td>-0.471635</td>\n",
       "      <td>-0.352775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163364</td>\n",
       "      <td>0.060336</td>\n",
       "      <td>0.113170</td>\n",
       "      <td>0.639825</td>\n",
       "      <td>0.581436</td>\n",
       "      <td>0.089397</td>\n",
       "      <td>-0.186249</td>\n",
       "      <td>-0.067916</td>\n",
       "      <td>-0.206023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.216182</td>\n",
       "      <td>0.245601</td>\n",
       "      <td>0.183347</td>\n",
       "      <td>0.588376</td>\n",
       "      <td>0.083498</td>\n",
       "      <td>-0.610692</td>\n",
       "      <td>0.323728</td>\n",
       "      <td>0.837952</td>\n",
       "      <td>-0.447431</td>\n",
       "      <td>-0.581264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142825</td>\n",
       "      <td>-0.118187</td>\n",
       "      <td>0.169801</td>\n",
       "      <td>0.740734</td>\n",
       "      <td>0.231928</td>\n",
       "      <td>0.244710</td>\n",
       "      <td>-0.208078</td>\n",
       "      <td>-0.378202</td>\n",
       "      <td>0.010910</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.020624  0.290489 -0.207166 -0.089109  0.014833 -0.474143  0.189333   \n",
       "1  0.036068  0.164903 -0.198505  0.190031 -0.106824 -0.548203  0.087713   \n",
       "2 -0.171994  0.380069 -0.126491  0.216998 -0.147193 -0.456888  0.173166   \n",
       "3 -0.250549  0.368768 -0.056130  0.201408 -0.159876 -0.356677 -0.119307   \n",
       "4 -0.216182  0.245601  0.183347  0.588376  0.083498 -0.610692  0.323728   \n",
       "\n",
       "          7         8         9  ...        91        92        93        94  \\\n",
       "0  0.530447 -0.180703 -0.247802  ...  0.060727  0.007973  0.108346  0.424585   \n",
       "1  0.760150 -0.502068 -0.783824  ...  0.170673 -0.185213  0.276593  0.814066   \n",
       "2  0.703797 -0.480871 -0.521802  ...  0.138489 -0.017147  0.224223  0.813675   \n",
       "3  0.579250 -0.471635 -0.352775  ...  0.163364  0.060336  0.113170  0.639825   \n",
       "4  0.837952 -0.447431 -0.581264  ...  0.142825 -0.118187  0.169801  0.740734   \n",
       "\n",
       "         95        96        97        98        99  target  \n",
       "0  0.117388  0.230643 -0.454489  0.036424 -0.022297       1  \n",
       "1  0.399272  0.251647 -0.380382 -0.173469 -0.159441       1  \n",
       "2  0.354883  0.284375 -0.369756 -0.171590 -0.127394       1  \n",
       "3  0.581436  0.089397 -0.186249 -0.067916 -0.206023       1  \n",
       "4  0.231928  0.244710 -0.208078 -0.378202  0.010910       1  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#append review column to word2vec dataframe\n",
    "df['target'] = data['review']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f34a74f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "96        0\n",
       "97        0\n",
       "98        0\n",
       "99        0\n",
       "target    0\n",
       "Length: 101, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a9bf19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X = df.drop('target',axis=1)\n",
    "y = df['target']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8024c9bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance-----------------------\n",
      "\n",
      "\n",
      "[[ 435  366]\n",
      " [ 212 1387]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.54      0.60       801\n",
      "           1       0.79      0.87      0.83      1599\n",
      "\n",
      "    accuracy                           0.76      2400\n",
      "   macro avg       0.73      0.71      0.71      2400\n",
      "weighted avg       0.75      0.76      0.75      2400\n",
      "\n",
      "0.7591666666666667\n"
     ]
    }
   ],
   "source": [
    "#model building\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "#check performance\n",
    "print(f'Model Performance-----------------------')\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed8a4a6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3199    0]\n",
      " [   0 6401]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3199\n",
      "           1       1.00      1.00      1.00      6401\n",
      "\n",
      "    accuracy                           1.00      9600\n",
      "   macro avg       1.00      1.00      1.00      9600\n",
      "weighted avg       1.00      1.00      1.00      9600\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#performance on training data\n",
    "y_pred_train = rf.predict(X_train)\n",
    "print(confusion_matrix(y_train,y_pred_train))\n",
    "print(classification_report(y_train,y_pred_train))\n",
    "print(accuracy_score(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2cf6ff49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance-----------------------\n",
      "\n",
      "\n",
      "[[ 461  340]\n",
      " [ 206 1393]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.58      0.63       801\n",
      "           1       0.80      0.87      0.84      1599\n",
      "\n",
      "    accuracy                           0.77      2400\n",
      "   macro avg       0.75      0.72      0.73      2400\n",
      "weighted avg       0.77      0.77      0.77      2400\n",
      "\n",
      "0.7725\n"
     ]
    }
   ],
   "source": [
    "#implement boosting algorithms\n",
    "from sklearn.ensemble import GradientBoostingClassifier,AdaBoostClassifier\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train,y_train)\n",
    "y_pred = gb.predict(X_test)\n",
    "#check performance\n",
    "print(f'Model Performance-----------------------')\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "57356383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kumarbaibhav/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance-----------------------\n",
      "\n",
      "\n",
      "[[ 446  355]\n",
      " [ 230 1369]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.56      0.60       801\n",
      "           1       0.79      0.86      0.82      1599\n",
      "\n",
      "    accuracy                           0.76      2400\n",
      "   macro avg       0.73      0.71      0.71      2400\n",
      "weighted avg       0.75      0.76      0.75      2400\n",
      "\n",
      "0.75625\n"
     ]
    }
   ],
   "source": [
    "ad = AdaBoostClassifier()\n",
    "ad.fit(X_train,y_train)\n",
    "y_pred = ad.predict(X_test)\n",
    "#check performance\n",
    "print(f'Model Performance-----------------------')\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd1fbdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kumarbaibhav/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance-----------------------\n",
      "\n",
      "\n",
      "[[ 446  355]\n",
      " [ 230 1369]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.56      0.60       801\n",
      "           1       0.79      0.86      0.82      1599\n",
      "\n",
      "    accuracy                           0.76      2400\n",
      "   macro avg       0.73      0.71      0.71      2400\n",
      "weighted avg       0.75      0.76      0.75      2400\n",
      "\n",
      "0.75625\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = AdaBoostClassifier()\n",
    "xgb.fit(X_train,y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "#check performance\n",
    "print(f'Model Performance-----------------------')\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ae26d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the parameter distributions\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(10, 50),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 5),\n",
    "}\n",
    "\n",
    "# Create a Random Forest model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Create RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=50, cv=5, scoring='recall', n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the random search to the data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best recall score\n",
    "best_params = random_search.best_params_\n",
    "best_recall = random_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Recall Score:\", best_recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d31a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Assume `rf` is your trained random forest model\n",
    "joblib_file = 'ad.pkl'\n",
    "joblib.dump(rf, joblib_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a41541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Assume `rf` is your trained random forest model\n",
    "joblib_file = 'rf.pkl'\n",
    "joblib.dump(rf, joblib_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26597f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "# from sklearn.metrics import make_scorer, f1_score\n",
    "# import numpy as np\n",
    "\n",
    "# # Define the parameter grid\n",
    "# param_distributions = {\n",
    "#     'n_estimators': [100, 200, 300, 400, 500],\n",
    "#     'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "#     'min_samples_split': [2, 5, 10, 15, 20],\n",
    "#     'min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "#     'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "# }\n",
    "\n",
    "# # Create a RandomForestClassifier\n",
    "# rf = RandomForestClassifier()\n",
    "\n",
    "# # Define stratified k-fold cross-validation\n",
    "# cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# # Use F1 score as the scoring metric\n",
    "# f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "# # Create RandomizedSearchCV object\n",
    "# random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_distributions,\n",
    "#                                    scoring=f1_scorer, cv=cv, n_jobs=-1, verbose=2, \n",
    "#                                    n_iter=100, random_state=42)\n",
    "\n",
    "# # Fit the model on the training data\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best parameters and the best F1 score\n",
    "# print(\"Best parameters found: \", random_search.best_params_)\n",
    "# print(\"Best F1 score: \", random_search.best_score_)\n",
    "\n",
    "# # Use the best model found by RandomizedSearchCV\n",
    "# best_rf = random_search.best_estimator_\n",
    "\n",
    "# # Predict using the best model\n",
    "# y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# # Calculate F1 score on the test set\n",
    "# test_f1_score = f1_score(y_test, y_pred)\n",
    "# print(\"Test set F1 score: \", test_f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e03fc11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#divide data into train and test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(data['reviewText'],data['review'],test_size=0.20)\n",
    "\n",
    "## Tokenize the text-creating indexes for words\n",
    "tokenizer=Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ecb1b064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust based on your data\n",
    "max_length = 100  \n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41b356a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "240/240 [==============================] - 21s 84ms/step - loss: 0.4682 - accuracy: 0.7794 - val_loss: 0.4244 - val_accuracy: 0.8094\n",
      "Epoch 2/5\n",
      "240/240 [==============================] - 21s 86ms/step - loss: 0.2562 - accuracy: 0.8958 - val_loss: 0.4659 - val_accuracy: 0.8052\n",
      "Epoch 3/5\n",
      "240/240 [==============================] - 21s 88ms/step - loss: 0.1567 - accuracy: 0.9397 - val_loss: 0.5563 - val_accuracy: 0.8073\n",
      "Epoch 4/5\n",
      "240/240 [==============================] - 21s 88ms/step - loss: 0.1112 - accuracy: 0.9613 - val_loss: 0.6641 - val_accuracy: 0.8026\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "#apply earlystopping criteria to monitor validation loss\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Initialize EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',            # Metric to monitor\n",
    "    patience=3,                    # Number of epochs to wait for improvement\n",
    "    restore_best_weights=True      # Restore the best weights\n",
    ")\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=20000, output_dim=128, input_length=max_length))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_pad, y_train, epochs=5, batch_size=32, validation_split=0.2,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "78d7948c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 2s 21ms/step - loss: 0.3983 - accuracy: 0.8154\n",
      "Test Loss: 0.3983\n",
      "Test Accuracy: 0.8154\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "60c7a8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 2s 22ms/step\n",
      "[[ 606  178]\n",
      " [ 265 1351]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.77      0.73       784\n",
      "           1       0.88      0.84      0.86      1616\n",
      "\n",
      "    accuracy                           0.82      2400\n",
      "   macro avg       0.79      0.80      0.80      2400\n",
      "weighted avg       0.82      0.82      0.82      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lets check performance metrics \n",
    "y_pred = model.predict(X_test_pad)\n",
    "y_pred = (y_pred>=0.5).astype(int)\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "daca8d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 239ms/step\n",
      "[[0.8615594]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "new_reviews = [\"I had an amazing experience at McDonald's today! The staff was super friendly, and my order was ready in less than five minutes. The Big Mac I ordered was fresh and tasted delicious, and the fries were hot and crispy, just the way I like them. The restaurant was clean, and the atmosphere was really pleasant. It was a quick and satisfying meal. I’ll definitely be coming back more often!\"]\n",
    "new_reviews_seq = tokenizer.texts_to_sequences(new_reviews)\n",
    "new_reviews_pad = pad_sequences(new_reviews_seq, maxlen=max_length)\n",
    "predictions = model.predict(new_reviews_pad)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
